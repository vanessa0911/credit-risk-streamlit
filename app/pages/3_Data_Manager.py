# app/pages/3_Data_Manager.py
import io
from pathlib import Path
import numpy as np
import pandas as pd
import streamlit as st
from pandas.api.types import is_numeric_dtype
from src.inference import expected_columns  # colonnes que le modÃ¨le attend

st.set_page_config(page_title="Gestion des donnÃ©es clients", layout="wide")
st.title("ğŸ§° Gestion des donnÃ©es clients (Ã©chantillonnage & compression)")

# ------------------------------
# 0) Chemins et garde-fous
# ------------------------------
ROOT = Path(__file__).resolve().parents[2]
RAW_DIR = ROOT / "data" / "raw"
PROC_DIR = ROOT / "data" / "processed"

def assert_raw_is_dir():
    if RAW_DIR.exists() and not RAW_DIR.is_dir():
        st.error(
            f"âš ï¸ `{RAW_DIR.relative_to(ROOT)}` **existe mais n'est pas un dossier**.\n\n"
            "Corrige via le terminal :\n"
            f"```\ncd {ROOT}\nmv data/raw data/raw.bak\nmkdir -p data/raw data/processed\n```\n"
            "Puis relance cette page."
        )
        st.stop()

assert_raw_is_dir()  # ne crÃ©e rien; vÃ©rifie seulement

st.markdown("""
Cette page crÃ©e une **version lÃ©gÃ¨re** (â‰¤ 25 MB) de tes donnÃ©es clients Ã  partir dâ€™un gros fichier :
1) **Choisis** un CSV/CSV.GZ dans `data/raw/` (ou uploade-le si la taille le permet).
2) **SÃ©lection** des colonnes utiles (celles du modÃ¨le, ajustables).
3) **Ã‰chantillonnage** automatique pour tenir sous la taille cible.
4) **Compression** en `data/processed/sample_clients.csv.gz` (prÃªt pour GitHub).
""")

# ------------------------------
# 1) Source (upload OU data/raw)
# ------------------------------
st.subheader("1) Choisir la source")

uploaded = st.file_uploader(
    "Uploader un CSV ou CSV.GZ (si possible). Astuce: pour Ã©viter l'erreur 413, dÃ©pose le fichier via l'explorateur dans `data/raw/`.",
    type=["csv", "gz"], accept_multiple_files=False,
)

existing = []
if RAW_DIR.is_dir():
    existing = sorted(list(RAW_DIR.glob("*.csv"))) + sorted(list(RAW_DIR.glob("*.csv.gz")))

choice = st.selectbox(
    "â€¦ ou sÃ©lectionner un fichier dÃ©jÃ  prÃ©sent dans `data/raw/`",
    ["â€” Aucun â€”"] + [str(p.relative_to(ROOT)) for p in existing],
    index=0
)

def read_any(path_or_buffer, name: str) -> pd.DataFrame:
    nm = name.lower()
    if nm.endswith(".csv.gz") or nm.endswith(".gz"):
        return pd.read_csv(path_or_buffer, compression="gzip", low_memory=False)
    return pd.read_csv(path_or_buffer, low_memory=False)

df, source_name = None, None
if uploaded is not None:
    source_name = uploaded.name
    with st.spinner(f"Lecture de {source_name}â€¦"):
        df = read_any(uploaded, source_name)
elif choice != "â€” Aucun â€”":
    source_name = choice
    with st.spinner(f"Lecture de {choice}â€¦"):
        df = read_any(ROOT / choice, choice)

if df is None:
    st.info("DÃ©pose un fichier **ou** choisis-en un dans `data/raw/` pour continuer.")
    st.stop()

st.success(f"Source chargÃ©e : **{source_name}** â€” {len(df):,} lignes, {df.shape[1]} colonnes")
with st.expander("AperÃ§u (10 premiÃ¨res lignes)"):
    st.dataframe(df.head(10), use_container_width=True)

# ------------------------------
# 2) Colonnes Ã  garder
# ------------------------------
st.subheader("2) Colonnes Ã  garder")

expected = expected_columns() or []
expected_set = set(expected)

id_candidates = [c for c in ["SK_ID_CURR", "client_id", "ID", "customer_id", "id"] if c in df.columns]
keep = [c for c in df.columns if c in expected_set]
for cid in id_candidates:
    if cid not in keep:
        keep.append(cid)
if not keep:
    st.warning("Aucune colonne du modÃ¨le trouvÃ©e. On sÃ©lectionne **toutes** les colonnes par dÃ©faut.")
    keep = list(df.columns)

sel_cols = st.multiselect("Colonnes conservÃ©es (tu peux ajuster) :", options=list(df.columns), default=keep)
df_sel = df[sel_cols].copy()

# Downcast numÃ©rique pour rÃ©duire la taille
for c in df_sel.columns:
    if is_numeric_dtype(df_sel[c]):
        as_int = pd.to_numeric(df_sel[c], errors="coerce", downcast="integer")
        if as_int.notna().sum() >= df_sel[c].notna().sum() * 0.9:
            df_sel[c] = as_int
        else:
            df_sel[c] = pd.to_numeric(df_sel[c], errors="coerce", downcast="float")

st.write(f"Colonnes retenues : **{len(sel_cols)}**")

# ------------------------------
# 3) Taille cible & Ã©chantillonnage
# ------------------------------
st.subheader("3) Ã‰chantillonnage & taille cible")
target_mb = st.slider("Taille maximale du fichier compressÃ© (.csv.gz)", 5, 25, 20, 1)
target_bytes = target_mb * 1024 * 1024

strat_col = st.selectbox(
    "Stratifier lâ€™Ã©chantillon (optionnel si une colonne cible existe)",
    ["â€” Aucune â€”"] + [c for c in df_sel.columns if c.lower() in {"target", "default", "y"}],
    index=0
)
if strat_col == "â€” Aucune â€”":
    strat_col = None

def estimate_rows_for_target(df_in: pd.DataFrame, target_bytes: int, sample_rows: int = 5000) -> int:
    n = len(df_in)
    test = df_in if n <= sample_rows else df_in.sample(sample_rows, random_state=42)
    buf = io.BytesIO()
    test.to_csv(buf, index=False, compression="gzip")
    bytes_per_row = max(1, buf.tell() / len(test))
    est = int(target_bytes / bytes_per_row)
    return max(1, min(n, est))

est_n = estimate_rows_for_target(df_sel, target_bytes)
st.write(f"**Estimation automatique** : ~ **{est_n:,}** lignes pour â‰ˆ {target_mb} MB.")

n_rows = st.number_input("Forcer le nombre de lignes (optionnel)", min_value=1, max_value=len(df_sel), value=est_n, step=1)

with st.spinner("CrÃ©ation de lâ€™Ã©chantillonâ€¦"):
    if n_rows >= len(df_sel):
        df_out = df_sel
    else:
        if strat_col and strat_col in df_sel.columns:
            df_out = (
                df_sel.groupby(strat_col, group_keys=False)
                .apply(lambda g: g.sample(max(1, int(np.ceil(len(g) * n_rows / len(df_sel)))), random_state=42))
            )
            if len(df_out) > n_rows:
                df_out = df_out.sample(n_rows, random_state=42)
        else:
            df_out = df_sel.sample(n_rows, random_state=42)

st.success(f"Ã‰chantillon crÃ©Ã© : **{len(df_out):,}** lignes, {df_out.shape[1]} colonnes")

with st.expander("AperÃ§u de lâ€™Ã©chantillon"):
    st.dataframe(df_out.head(20), use_container_width=True)

# ------------------------------
# 4) Sauvegarde compressÃ©e
# ------------------------------
st.subheader("4) Sauvegarder en .csv.gz (prÃªt pour GitHub)")
out_path = PROC_DIR / "sample_clients.csv.gz"

if st.button("ğŸ’¾ Enregistrer `data/processed/sample_clients.csv.gz`"):
    # On crÃ©e **seulement** le dossier processed si besoin
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with st.spinner("Ã‰criture du fichier compressÃ©â€¦"):
        df_out.to_csv(out_path, index=False, compression="gzip")

    size = out_path.stat().st_size
    st.success(f"Fichier Ã©crit : **{out_path.relative_to(ROOT)}** â€” **{size/1024/1024:.2f} MB**")
    st.download_button(
        "â¬‡ï¸ TÃ©lÃ©charger ce fichier",
        data=out_path.read_bytes(),
        file_name="sample_clients.csv.gz",
        mime="application/gzip",
    )

st.caption("Astuce : pour Ã©viter les erreurs 413, uploade ton fichier via lâ€™explorateur Codespaces dans `data/raw/`.")

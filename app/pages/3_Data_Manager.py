# app/pages/3_Data_Manager.py
import io
from pathlib import Path
import numpy as np
import pandas as pd
import streamlit as st
from pandas.api.types import is_numeric_dtype

from src.inference import expected_columns  # colonnes que le modÃ¨le attend

st.set_page_config(page_title="Gestion des donnÃ©es clients", layout="wide")
st.title("ğŸ§° Gestion des donnÃ©es clients (Ã©chantillonnage & compression)")

ROOT = Path(__file__).resolve().parents[2]
RAW_DIR = ROOT / "data" / "raw"
PROC_DIR = ROOT / "data" / "processed"
PROC_DIR.mkdir(parents=True, exist_ok=True)
RAW_DIR.mkdir(parents=True, exist_ok=True)

st.markdown(
    """
Cette page crÃ©e une **version lÃ©gÃ¨re** (â‰¤ 25 MB) de tes donnÃ©es clients Ã  partir dâ€™un gros fichier :
1) **DÃ©pose** un CSV ou CSV.GZ (ou choisis-en un dÃ©jÃ  prÃ©sent dans `data/raw/`).
2) On **garde** les colonnes utiles (celles du modÃ¨le, ajustables).
3) On **Ã©chantillonne** automatiquement une taille cible.
4) On **compresse** en `data/processed/sample_clients.csv.gz` (prÃªt pour GitHub).
"""
)

# -------------------------------
# 1) Source : upload OU fichier local dans data/raw/
# -------------------------------
st.subheader("1) Choisir la source")

uploaded = st.file_uploader(
    "DÃ©poser un fichier (CSV ou CSV.GZ). Conseil: pour Ã©viter l'erreur 413, uploade plutÃ´t via l'explorateur Codespaces dans data/raw/",
    type=["csv", "gz"],
    accept_multiple_files=False,
)

existing_files = sorted(list(RAW_DIR.glob("*.csv"))) + sorted(list(RAW_DIR.glob("*.csv.gz")))
choice = st.selectbox(
    "â€¦ ou sÃ©lectionner un fichier dÃ©jÃ  prÃ©sent dans data/raw/",
    ["â€” Aucun â€”"] + [str(f.relative_to(ROOT)) for f in existing_files],
    index=0
)

def read_any(path_or_buffer, name: str) -> pd.DataFrame:
    """Lit CSV ou CSV.GZ selon l'extension / le nom."""
    nm = name.lower()
    if nm.endswith(".csv.gz") or nm.endswith(".gz"):
        return pd.read_csv(path_or_buffer, compression="gzip", low_memory=False)
    return pd.read_csv(path_or_buffer, low_memory=False)

df = None
source_name = None

if uploaded is not None:
    source_name = uploaded.name
    with st.spinner(f"Lecture de {source_name}â€¦"):
        df = read_any(uploaded, source_name)
elif choice != "â€” Aucun â€”":
    source_name = choice
    with st.spinner(f"Lecture de {choice}â€¦"):
        df = read_any(ROOT / choice, choice)

if df is None:
    st.info("DÃ©pose un fichier **ou** choisis-en un dans `data/raw/` pour continuer.")
    st.stop()

st.success(f"Source chargÃ©e : **{source_name}** â€” {len(df):,} lignes, {df.shape[1]} colonnes")
with st.expander("AperÃ§u (10 premiÃ¨res lignes)"):
    st.dataframe(df.head(10), use_container_width=True)

# -------------------------------
# 2) Colonnes Ã  garder (auto + ajustables)
# -------------------------------
st.subheader("2) Colonnes Ã  garder")

expected = expected_columns() or []
expected_set = set(expected)

# On garde colonnes du modÃ¨le + un identifiant si prÃ©sent
id_candidates = [c for c in ["SK_ID_CURR", "client_id", "ID", "customer_id", "id"] if c in df.columns]
keep = [c for c in df.columns if c in expected_set]
for cid in id_candidates:
    if cid not in keep:
        keep.append(cid)

if not keep:
    st.warning("Aucune colonne du modÃ¨le trouvÃ©e. On sÃ©lectionne **toutes** les colonnes par dÃ©faut.")
    keep = list(df.columns)

sel_cols = st.multiselect(
    "Colonnes conservÃ©es (tu peux ajuster) :",
    options=list(df.columns),
    default=keep,
)

df_sel = df[sel_cols].copy()

# Downcast numÃ©rique pour rÃ©duire la taille
for c in df_sel.columns:
    if is_numeric_dtype(df_sel[c]):
        as_int = pd.to_numeric(df_sel[c], errors="coerce", downcast="integer")
        if as_int.notna().sum() >= df_sel[c].notna().sum() * 0.9:
            df_sel[c] = as_int
        else:
            df_sel[c] = pd.to_numeric(df_sel[c], errors="coerce", downcast="float")

st.write(f"Colonnes retenues : **{len(sel_cols)}**")

# -------------------------------
# 3) Taille cible & Ã©chantillonnage
# -------------------------------
st.subheader("3) Ã‰chantillonnage & taille cible")
target_mb = st.slider("Taille maximale du fichier compressÃ© (.csv.gz)", 5, 25, 20, 1)
target_bytes = target_mb * 1024 * 1024

strat_col = st.selectbox(
    "Stratifier lâ€™Ã©chantillon (optionnel si une colonne cible existe)", 
    ["â€” Aucune â€”"] + [c for c in df_sel.columns if c.lower() in {"target", "default", "y"}],
    index=0
)
if strat_col == "â€” Aucune â€”":
    strat_col = None

def estimate_rows_for_target(df_in: pd.DataFrame, target_bytes: int, sample_rows: int = 5000) -> int:
    """Estime le nombre de lignes pour respecter la taille cible aprÃ¨s compression gzip."""
    n = len(df_in)
    test = df_in if n <= sample_rows else df_in.sample(sample_rows, random_state=42)
    buf = io.BytesIO()
    test.to_csv(buf, index=False, compression="gzip")
    bytes_per_row = max(1, buf.tell() / len(test))
    est = int(target_bytes / bytes_per_row)
    return max(1, min(n, est))

est_n = estimate_rows_for_target(df_sel, target_bytes)
st.write(f"**Estimation automatique** : ~ **{est_n:,}** lignes pour â‰ˆ {target_mb} MB.")

n_rows = st.number_input("Forcer le nombre de lignes (optionnel)", min_value=1, max_value=len(df_sel), value=est_n, step=1)

with st.spinner("CrÃ©ation de lâ€™Ã©chantillonâ€¦"):
    if n_rows >= len(df_sel):
        df_out = df_sel
    else:
        if strat_col and strat_col in df_sel.columns:
            df_out = (
                df_sel.groupby(strat_col, group_keys=False)
                .apply(lambda g: g.sample(max(1, int(np.ceil(len(g) * n_rows / len(df_sel)))), random_state=42))
            )
            if len(df_out) > n_rows:
                df_out = df_out.sample(n_rows, random_state=42)
        else:
            df_out = df_sel.sample(n_rows, random_state=42)

st.success(f"Ã‰chantillon crÃ©Ã© : **{len(df_out):,}** lignes, {df_out.shape[1]} colonnes")

with st.expander("AperÃ§u de lâ€™Ã©chantillon"):
    st.dataframe(df_out.head(20), use_container_width=True)

# -------------------------------
# 4) Sauvegarde compressÃ©e + tÃ©lÃ©chargement
# -------------------------------
st.subheader("4) Sauvegarder en .csv.gz (prÃªt pour GitHub)")
out_path = PROC_DIR / "sample_clients.csv.gz"

if st.button("ğŸ’¾ Enregistrer `data/processed/sample_clients.csv.gz`"):
    with st.spinner("Ã‰criture du fichier compressÃ©â€¦"):
        df_out.to_csv(out_path, index=False, compression="gzip")

    size = out_path.stat().st_size
    st.success(f"Fichier Ã©crit : **{out_path.relative_to(ROOT)}** â€” **{size/1024/1024:.2f} MB**")
    st.download_button(
        "â¬‡ï¸ TÃ©lÃ©charger ce fichier",
        data=out_path.read_bytes(),
        file_name="sample_clients.csv.gz",
        mime="application/gzip",
    )

st.caption("Astuce : pour Ã©viter les erreurs 413, uploade ton fichier via lâ€™**explorateur Codespaces** dans `data/raw/`.")
